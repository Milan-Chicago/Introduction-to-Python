{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "running-pavilion",
   "metadata": {},
   "source": [
    "# Machine Learning Basics with Scikit-learn: Day 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-turning",
   "metadata": {},
   "source": [
    "## Unsupervised learning\n",
    "Yesterday, we explored supervised machine learning models, which are training based on labeled data. In contrast, **unsupervised learning** uses machine learning algorithms to analyze and cluster unlabeled datasets. These algorithms discover hidden patterns or data groupings without the need for human intervention. Its ability to discover similarities and differences in information make it the ideal solution for exploratory data analysis, cross-selling strategies, customer segmentation, and image recognition. \n",
    "\n",
    "Many unsupervised learning models are available in [scikit-learn](https://scikit-learn.org/stable/unsupervised_learning.html). Today, We will focus on **clustering**. These functions seek to learn from the properties of the data an optimal division. The final goal is to label the data in groups of points.\n",
    "\n",
    "We will start importing the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-blank",
   "metadata": {},
   "source": [
    "Let's create some data points and we will use them to create our clusters. We will use the function `make_blobs` to 300 points spread among create five clusters in a 2D plane.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_blobs(n_samples=300, centers=5, cluster_std=0.60, random_state=0)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-extreme",
   "metadata": {},
   "source": [
    "## k-Means\n",
    "One of simplest algorithms to understand is *k-means* clustering. This clustering algorithm aims to partition *n* observations into *k* clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster. This algorithm **requires the number of clusters to be specified.** It scales well to large number of samples and has been used across a large range of application areas in many different fields. For more information about this algorithm, please check the [documentation](https://scikit-learn.org/stable/modules/clustering.html#k-means).\n",
    "\n",
    "Let's start creating a model using the data created for this exercise. We will set five clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-insulation",
   "metadata": {},
   "source": [
    "We will visualize how each point was assinged to a cluster. A color represents a specific cluster. In total, we will see five groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50)\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-index",
   "metadata": {},
   "source": [
    "And we can get more information about the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'x': X[:,0], 'y': X[:,1], 'cluster': kmeans.labels_})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-pacific",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "The algorithm easily found the natural clusters from this data distribution. How would the algorithm predict the dots if we set 3 or 6 clusters? Run the algorithm with different number of clusters, and plot the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot three clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot five clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-participation",
   "metadata": {},
   "source": [
    "### Using real data\n",
    "We will use the wine dataset to check potential clusters. We will use the first two attributes: `alcohol` and `malic_acid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "X = wine.data[:,:2]\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-district",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Create a k-means model with 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot three clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-reader",
   "metadata": {},
   "source": [
    "### How to determine the optimal number of clusters?\n",
    "\n",
    "Should we create three clusters? Four? Five? There is a visual approach called **elbow method.** The idea behind is to implement k-means clustering on a given dataset for a range of values of number of clusters *k* (e.g k=1 to 10), and for each value of *k*, calculate the sum of squared errors (SSE).\n",
    "\n",
    "Elbow method plot a line graph of the SSE for each value of *k*. If the line graph looks like an arm, the \"elbow\" on the arm is the value of optimal *k* (number of the cluster). k-means is used to minimize SSE. SSE tends to decrease toward 0 as we increase k and SSE is 0 when k is equal to the number of data points in the dataset, because then each data point is its own cluster, and there is no error between it and the center of its cluster.\n",
    "\n",
    "The goal is to choose a optimal value of *k* that still has a low SSE, and the elbow usually represents where we start to have diminishing returns by increasing k.\n",
    "\n",
    "Let's plot the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = {}\n",
    "\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X)\n",
    "    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-stuart",
   "metadata": {},
   "source": [
    "By checking this plot, we can create 3 clusters is the optimal number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-transaction",
   "metadata": {},
   "source": [
    "### Some applications\n",
    "One interesting application of clustering is in color compression within images. For example, an image with millions of colors. In most images, a large number of the colors will be unused, and many of the pixels in the image will have similar or even identical colors.\n",
    "\n",
    "RGB can take values from 0 to 255 (256 in total). Since we have three colors, we can have 256 * 256 * 256 = 16,777,216. \n",
    "\n",
    "<img src=\"https://mk0nixsensorcommcpqi.kinstacdn.com/wp-content/uploads/2018/02/rgb_model.gif\" alt=\"\" width=\"400\" height=\"244\">\n",
    "\n",
    "In other words, 16 million different colors can be represented in the RGB color space. \n",
    "\n",
    "For example, consider the image shown in the following figure, which is from the datasets module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "ax = plt.axes(xticks=[], yticks=[])\n",
    "ax.imshow(china);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-stone",
   "metadata": {},
   "source": [
    "The image itself is stored in a three-dimensional array of size (height, width, RGB), containing red/blue/green contributions as integers from 0 to 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "china.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-bailey",
   "metadata": {},
   "source": [
    "The picture's size is 427 x 640 px. And given that each pixel saves colors with three different numbers (R,G,B), we will have 427 * 640 * 3 = 819,840 cells of information. \n",
    "\n",
    "Let's check the first pixel of this picture (x=0,y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "china[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-silicon",
   "metadata": {},
   "source": [
    "One way we can view this set of pixels is as a cloud of points in a three-dimensional color space. We will reshape the data to `n_samples` x `n_features`, and rescale the colors so that they lie between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = china / 255.0 # use 0...1 scale\n",
    "data = data.reshape(427 * 640, 3)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-interference",
   "metadata": {},
   "source": [
    "How many unique colors do we have in this picture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_original_colors = len(np.unique(data, axis=0))\n",
    "unique_original_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-improvement",
   "metadata": {},
   "source": [
    "We have about 96,600 unique colors in this picture. Can we reduce the number of colors to 16? \n",
    "Let's reduce these colors to just 16 colors, using a k-means clustering across the pixel space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 16)\n",
    "kmeans.fit(data)\n",
    "new_colors = kmeans.cluster_centers_[kmeans.predict(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_new_colors = len(np.unique(new_colors, axis=0))\n",
    "unique_new_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-music",
   "metadata": {},
   "source": [
    "We replaced each color to an approximation. Instead of using 16 millions of colors, we are now using 16 colors. How would the picture look after this transformation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "china_recolored = new_colors.reshape(china.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6),\n",
    "                       subplot_kw=dict(xticks=[], yticks=[]))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "ax[0].imshow(china)\n",
    "ax[0].set_title('Original Image', size=16)\n",
    "ax[1].imshow(china_recolored)\n",
    "ax[1].set_title('16-color Image', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-primary",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "How would this picture look with 8 colors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the k-mean model and calculate the new colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the new picture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-defendant",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "We explore another broadly used of unsupervised algorithms called **principal component analysis** (PCA). PCA is fundamentally a dimensionality reduction algorithm. The goal of this method is to find a list of the principal axes in the data and using those axes to describe the dataset. Since we could have hundreds of features, PCA looks for reducing the number of dimensions and find *components* that can aggregate their information.\n",
    "\n",
    "Its behavior is easiest to visualize by looking at a two-dimensional dataset. Consider the following 300 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = np.dot(rng.rand(2, 2), rng.randn(2, 300)).T\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-resource",
   "metadata": {},
   "source": [
    "By eye, it is clear that there is a nearly linear relationship between the x and y variables. Rather than attempting to predict the y values from the x values, we aim to understand the relationship between the x and y values.\n",
    "\n",
    "In PCA, this relationship is quantified by finding a list of the principal axes in the data, and using those axes to describe the dataset. Using *scikit-learn*'s PCA estimator, we can compute this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-mistake",
   "metadata": {},
   "source": [
    "PCA now created two components that explain most of the variance among the data. How much variance does each component explain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-owner",
   "metadata": {},
   "source": [
    "The first component explains 97.4% the variance among the dataset (0.77 units of variance), while the second component explains 0.02% (0.02 units of variance).\n",
    "\n",
    "To see what these numbers mean, let's visualize them as vectors over the input data, using the \"components\" to define the direction of the vector, and the \"explained variance\" to define the squared-length of the vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "    v = vector * 3 * np.sqrt(length)\n",
    "    ax = plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', pca.mean_ + v, pca.mean_, arrowprops=arrowprops)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-cancellation",
   "metadata": {},
   "source": [
    "These black arrows represent the principal axes of the data, and the length of the arrow is an indication of how \"important\" that axis is in describing the distribution of the data. More precisely, it is a measure of the variance of the data when projected onto that axis. The projection of each data point onto the principal axes are the \"principal components\" of the data.\n",
    "\n",
    "This transformation from data axes to principal axes is an affine transformation, which basically means it is composed of a translation, rotation, and uniform scaling.\n",
    "\n",
    "While this algorithm to find principal components may seem like just a mathematical curiosity, it turns out to have very far-reaching applications in the world of machine learning and data exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-vertex",
   "metadata": {},
   "source": [
    "### Using PCA for data reduction\n",
    "\n",
    "Using PCA for dimensionality reduction involves zeroing out one or more of the smallest principal components, resulting in a lower-dimensional projection of the data that preserves the maximal data variance.\n",
    "\n",
    "Here is an example of using PCA as a dimensionality reduction transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-coordination",
   "metadata": {},
   "source": [
    "The wine dataset containst 13 features. Running a PCA will allow us reduce the number of features from 13 to 2, without losing too much data variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-crisis",
   "metadata": {},
   "source": [
    "We can observe that most variance is explained by one component (99.8%). In other words, most data variation can be explained by one component.\n",
    "\n",
    "Let's check visually how each observation is located on this PCA reduction. We will paint each observation according to the wine class (`y`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], wine.target_names):\n",
    "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of the wine dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-paste",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Let's try this PCA reduction exercise again using the Boston dataset. Create two components of the Boston dataset using PCA, check how much variance is explained by each component, and plot the PCA plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the new PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the explained variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the explained variance ratio (percentage of variance explained by each component)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-float",
   "metadata": {},
   "source": [
    "We kept the final plot. You will see that darker green means a higher house value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure()\n",
    "#plt.scatter(X_boston[:, 0], X_boston[:, 1], c=y, cmap='Greens')\n",
    "#plt.title('PCA of the Boston dataset')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-booth",
   "metadata": {},
   "source": [
    "### Choosing the number of components\n",
    "Like k-Means, we can estimate how many components are needed to describe the data. This can be determined by looking at the cumulative explained variance ratio as a function of the number of components. We will run this exercise with the Boston dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(boston.data)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-nudist",
   "metadata": {},
   "source": [
    "This curve quantifies how much of the total, 13-dimensional variance is contained within the first *N* components. For example, we see that the first component contains approximately 96% of the variance, and with 3 components we are close to describe 100% of the variance.\n",
    "\n",
    "The two-dimensional projection did not loose a lot of information (as measured by the explained variance). Having two components retains close to 98% of the variance. Looking at this plot for a high-dimensional dataset can help us understand the level of redundancy present in multiple observations.\n",
    "\n",
    "Let's compute the PCA using three components. How would the components like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "X_boston = pca.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(10, 8))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "ax.scatter(X_boston[:, 0], X_boston[:, 1], X_boston[:, 2], c=y, cmap='Greens', edgecolor='k')\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-surfing",
   "metadata": {},
   "source": [
    "### Face recognition\n",
    "We will check the use of PCA for face recognition. We will load the [Load the Labeled Faces in the Wild (LFW) people dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html) available in scikit-learn. This dataset is a collection of JPEG pictures of famous people collected over the internet, all details are available on the [official website](http://vis-www.cs.umass.edu/lfw/). Each picture is centered on a single face. The typical task is called Face Verification: given a pair of two pictures, a binary classifier must predict whether the two images are from the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = fetch_lfw_people(min_faces_per_person=40)\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 10, figsize=(18, 10),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(faces.data[i].reshape(62, 47), cmap='binary_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-behavior",
   "metadata": {},
   "source": [
    "Because this is a large dataset with a high-dimensionality (62 height pixels * 47 width pixels = 2,914 pixels per image), we can use PCA components to reduce the information used for each one of these pictures. Instead of using these ~3,000 features, let's try to reduce it to 150. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=150)\n",
    "pca.fit(faces.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-designer",
   "metadata": {},
   "source": [
    "In this case, it can be interesting to visualize the images associated with the first several principal components (these components are technically known as \"eigenvectors,\" so these types of images are often called \"eigenfaces\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 10, figsize=(18, 10),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(pca.components_[i].reshape(62, 47), cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-mounting",
   "metadata": {},
   "source": [
    "We sum all the explained variance of each component to check how much variance is explained by these 150 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-assessment",
   "metadata": {},
   "source": [
    "We see that 150 components account for 94% of the variance. That would lead us to believe that using these 150 components, we would recover most of the essential characteristics of the original data. To make this more concrete, we can compare the input images with the images reconstructed from these 150 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the components and projected faces\n",
    "components = pca.transform(faces.data)\n",
    "projected = pca.inverse_transform(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the picture\n",
    "fig, axes = plt.subplots(6, 10, figsize=(18, 10),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(projected[i].reshape(62, 47), cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-tuesday",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "Try this exercise using the [Olivetti faces dataset](https://scikit-learn.org/stable/datasets/real_world.html#olivetti-faces-dataset) This dataset contains a set of face images taken between April 1992 and April 1994 at AT&T Laboratories Cambridge. The sklearn.datasets.fetch_olivetti_faces function is the data fetching / caching function that downloads the data archive from AT&T. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces2 = fetch_olivetti_faces(shuffle=True, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(faces2.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-longer",
   "metadata": {},
   "source": [
    "**Note**: The image size is 64 x 64. You must update the reshape command from `reshape(62, 47)` to `reshape(64, 64)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 10, figsize=(18, 10),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(faces2.data[i].reshape(64, 64), cmap='binary_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the components and projected faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the artificial picture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-microphone",
   "metadata": {},
   "source": [
    "## More Resources if you are interested in learning more\n",
    "* [In Depth: k-Means Clustering](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)\n",
    "* [In Depth: Principal Component Analysis](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
